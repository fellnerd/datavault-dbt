# Lessons Learned - Data Vault 2.1 mit dbt auf Azure

## Projektkontext
PoC f√ºr eine virtualisierte Data Vault 2.1 Architektur als wiederverwendbares SaaS-Template.

---

## Entscheidungen & Begr√ºndungen

### 1. dbt statt Stored Procedures
**Entscheidung:** dbt Core mit automate-dv Package statt T-SQL Stored Procedures

**Begr√ºndung:**
- Versionskontrolle (Git) nativ integriert
- Wiederverwendbare Macros f√ºr verschiedene Kunden
- Lineage und Dokumentation automatisch
- Community-Support und Best Practices (automate-dv)

### 2. Hybrid: Raw Vault physisch, Business Vault virtuell
**Entscheidung:** Raw Vault als echte Tabellen, Business Vault als Views

**Begr√ºndung:**
- Raw Vault ben√∂tigt Insert-Only Performance
- Business Vault ist nur berechnete Sichten
- Kosteneinsparung bei Azure SQL

### 3. SHA2_256 als Hash-Algorithmus
**Entscheidung:** SHA2_256 ‚Üí CHAR(64) f√ºr alle Hash Keys

**Begr√ºndung:**
- Industriestandard f√ºr Data Vault
- Native Unterst√ºtzung in SQL Server (HASHBYTES)
- Keine Kollisionsgefahr bei erwarteten Datenmengen
- 64 Zeichen als feste L√§nge gut handhabbar

### 4. Linux VM f√ºr dbt
**Entscheidung:** dbt auf Linux VM statt Mac/Windows

**Begr√ºndung:**
- ODBC-Treiber stabiler unter Linux
- Einfachere Deployment-Vorbereitung f√ºr Container
- VS Code Remote SSH erm√∂glicht komfortable Entwicklung

---

## Probleme & L√∂sungen

### Problem 1: automate-dv Hash Macros inkompatibel
**Symptom:** Fehler bei Verwendung von automate-dv hash() Macro

**Ursache:** automate-dv optimiert f√ºr Snowflake/BigQuery, SQL Server anders

**L√∂sung:** Eigene Hash-Logik im Staging Model:
```sql
CONVERT(CHAR(64), HASHBYTES('SHA2_256', 
    ISNULL(CAST(column AS NVARCHAR(MAX)), '')
), 2) AS hk_entity
```

### Problem 2: Columnstore Index nicht verf√ºgbar
**Symptom:** `CREATE TABLE failed because the following SET options have incorrect settings: 'ANSI_NULLS'`

**Ursache:** Azure SQL Basic Tier unterst√ºtzt keine Columnstore Indexes

**L√∂sung:** In dbt_project.yml und Model-Config:
```yaml
+as_columnstore: false
```

### Problem 3: Schema-Prefix unerw√ºnscht
**Symptom:** Schemas wurden als `dv_stg` statt `stg` erstellt

**Ursache:** dbt-sqlserver f√ºgt Target-Schema als Prefix hinzu

**L√∂sung:** Custom Macro in `macros/generate_schema_name.sql`:
```sql
{% macro generate_schema_name(custom_schema_name, node) %}
    {{ custom_schema_name | trim }}
{% endmacro %}
```

### Problem 4: profiles.yml im Repo
**Symptom:** Sicherheitsrisiko durch Credentials im Git

**L√∂sung:** 
- profiles.yml in ~/.dbt/ (au√üerhalb Repo)
- .gitignore mit `profiles.yml`
- Azure CLI Authentication (keine Passw√∂rter)

---

## Best Practices (gelernt)

### dbt Projektstruktur
```
models/
  staging/           # Views mit Hash-Berechnung
  raw_vault/
    hubs/            # Business Key + Metadata
    satellites/      # Attribute + Hash Diff
    links/           # Beziehungen
  business_vault/    # PITs, Bridges (virtuell)
```

### Staging Pattern
1. External Table als Source (`stg.ext_*`)
2. Staging View berechnet alle Hash Keys (`stg.stg_*`)
3. Hash Key = Business Key Hash
4. Hash Diff = Alle Attribute Hash (f√ºr Change Detection)

### Satellite Change Detection
```sql
LEFT JOIN ON hk AND NOT EXISTS (sat mit gleichem hd)
```
Statt: Timestamp-basierter Vergleich

---

## N√§chste Schritte

1. **Link-Tables** - Verbindung company_client zu countries
2. **Incremental Test** - Delta-Load validieren
3. **CI/CD** - Azure DevOps Pipeline f√ºr dbt run
4. **Weitere Entities** - contractor, supplier
5. **Business Vault** - PIT und Bridge Views

---

## Technische Referenz

### Verbindungsdaten
- **Server:** sql-datavault-weu-001.database.windows.net
- **Database:** DataVault
- **Auth:** Azure CLI (az login)

### VM Zugang
```bash
ssh dimetrics-local-dev  # Alias in ~/.ssh/config
cd ~/projects/datavault-dbt
source .venv/bin/activate
```

### Aktueller Stand ($(date +%Y-%m-%d))
- ‚úÖ Hub: vault.hub_company_client (7.501 Records)
- ‚úÖ Satellite: vault.sat_company_client (7.501 Records)
- üîÑ Link: Noch zu erstellen
